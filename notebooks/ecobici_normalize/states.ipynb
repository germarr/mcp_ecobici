{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "from datetime import datetime\n",
    "\n",
    "def get_county_from_coordinates(lat, lon, api_key):\n",
    "    # Create a client\n",
    "    gmaps = googlemaps.Client(key=api_key)\n",
    "    \n",
    "    # Reverse geocode the coordinates\n",
    "    result = gmaps.reverse_geocode((lat, lon))\n",
    "    \n",
    "    # Look for administrative_area_level_2 (county/alcald√≠a) in the results\n",
    "    county = None\n",
    "    if result:\n",
    "        for component in result[0]['address_components']:\n",
    "            if 'administrative_area_level_2' in component['types']:\n",
    "                county = component['long_name']\n",
    "                break\n",
    "    \n",
    "    return county\n",
    "\n",
    "# Example usage:\n",
    "# Replace with your actual API key\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv('google_key')\n",
    "\n",
    "# county = get_county_from_coordinates(19.4326, -99.1332, api_key)\n",
    "# print(county)\n",
    "# county = get_county_from_coordinates(19.4326, -99.1332, api_key)\n",
    "# print(county)\n",
    "\n",
    "for station_info in stations.to_dict('records')[0:1]:\n",
    "     aah = get_county_from_coordinates(lat=station_info['lat_end'], lon=station_info['lon_end'], api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "from datetime import datetime\n",
    "\n",
    "gmaps = googlemaps.Client(key=api_key)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for station_info in stations[['ciclo_estacionarribo','lat_end','lon_end']].drop_duplicates().to_dict('records')[0:10]:\n",
    "    \n",
    "    regions_df = []\n",
    "    example = gmaps.reverse_geocode((station_info['lat_end'], station_info['lon_end']))\n",
    "\n",
    "    for i in example[0]['address_components']:\n",
    "        regions_df.append({\n",
    "            \"long_name\": i['long_name'],\n",
    "            \"types\": \",\".join(i['types'])\n",
    "        })\n",
    "    \n",
    "    result_df = pd.DataFrame(regions_df)\n",
    "    result_df['ciclo_estacionarribo'] = station_info['ciclo_estacionarribo']\n",
    "\n",
    "    all_results.append(result_df)\n",
    "\n",
    "import time\n",
    "e_list = []\n",
    "for i,station_info in enumerate(stations[['ciclo_estacionarribo','lat_end','lon_end']].drop_duplicates().to_dict('records')):\n",
    "    \n",
    "    example = gmaps.reverse_geocode((station_info['lat_end'], station_info['lon_end']))\n",
    "    export_json = {\"ciclo_estacionarribo\":station_info['ciclo_estacionarribo'],\"googloe_maps_response\": example}\n",
    "    e_list.append(export_json)\n",
    "    # To avoid hitting the API rate limit, we can add a sleep time\n",
    "    if i % 30 == 0:\n",
    "        print(f\"Processed {i} stations, sleeping for 5 second to avoid rate limiting...\")\n",
    "        time.sleep(5)  # Sleep for 5 second between requests\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open('/Volumes/T7 Shield/Ecobici/stations_geocode_results.json', 'w') as f:\n",
    "    json.dump(e_list, f, indent=4)\n",
    "print(f\"Saved geocoding results for {len(e_list)} stations to 'stations_geocode_results.json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youtube  Keys\n",
    "API_KEY = os.getenv('openai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Volumes/T7 Shield/Ecobici/stations_geocode_results.json') as f:\n",
    "    alcaldias = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with ciclo_estacionarribo and formatted_address\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        'ciclo_estacionarribo': item['ciclo_estacionarribo'],\n",
    "        'formatted_address': item['googloe_maps_response'][0]['formatted_address']\n",
    "    }\n",
    "    for item in alcaldias\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "def get_alcaldia(address_components):\n",
    "    for component in address_components:\n",
    "        if 'sublocality_level_1' in component['types']:\n",
    "            return component['long_name']\n",
    "    return None\n",
    "\n",
    "print(get_alcaldia(alcaldias[1]['googloe_maps_response'][0]['address_components']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 386\n",
      "- Max allowed response tokens: 3710\n",
      "- Response tokens: 712\n",
      "- Tokens left on table: 2998\n",
      "- Total used: 1098\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import math\n",
    "import json\n",
    "import tiktoken\n",
    "\n",
    "def count_tokens(text, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"Count tokens for a given text using tiktoken.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def extract_alcaldia_colonia_zip(addresses, api_key, max_tokens=4096, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Extract alcaldia, colonia, and zip code from a list of addresses using OpenAI API.\n",
    "\n",
    "    Parameters:\n",
    "        addresses (list): List of addresses to process.\n",
    "        api_key (str): Your OpenAI API key.\n",
    "        max_tokens (int): Maximum token limit for the OpenAI model.\n",
    "        model (str): OpenAI model to use.\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            \"results\": {address: {\"alcaldia\": ..., \"colonia\": ..., \"zip_code\": ...}, ...},\n",
    "            \"token_summary\": {\n",
    "                \"total_prompt_tokens\": int,\n",
    "                \"total_response_tokens\": int,\n",
    "                \"total_tokens_used\": int,\n",
    "                \"total_tokens_left_on_table\": int\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "    avg_tokens_per_address = 20\n",
    "    max_addresses = math.floor((max_tokens - 500) / avg_tokens_per_address)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Token summary stats\n",
    "    total_prompt_tokens = 0\n",
    "    total_response_tokens = 0\n",
    "    total_tokens_left = 0\n",
    "\n",
    "    for i in range(0, len(addresses), max_addresses):\n",
    "        batch = addresses[i:i + max_addresses]\n",
    "        prompt = (\n",
    "            \"Extract the alcaldia, colonia, and zip code from the following addresses in JSON format. \"\n",
    "            \"Each address should be a key, and the value should be a dictionary with keys 'alcaldia', 'colonia', and 'zip_code'.\\n\\n\"\n",
    "            + \"\\n\".join(batch)\n",
    "        )\n",
    "\n",
    "        prompt_tokens = count_tokens(prompt, model)\n",
    "        allowed_response_tokens = max_tokens - prompt_tokens\n",
    "\n",
    "        print(f\"\\nBatch {i // max_addresses + 1}:\")\n",
    "        print(f\"- Prompt tokens: {prompt_tokens}\")\n",
    "        print(f\"- Max allowed response tokens: {allowed_response_tokens}\")\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=allowed_response_tokens,\n",
    "                temperature=0\n",
    "            )\n",
    "\n",
    "            response_content = response.choices[0].message.content\n",
    "            response_tokens = count_tokens(response_content, model)\n",
    "            unused_tokens = allowed_response_tokens - response_tokens\n",
    "\n",
    "            print(f\"- Response tokens: {response_tokens}\")\n",
    "            print(f\"- Tokens left on table: {unused_tokens}\")\n",
    "            print(f\"- Total used: {prompt_tokens + response_tokens}\")\n",
    "\n",
    "            # Tally\n",
    "            total_prompt_tokens += prompt_tokens\n",
    "            total_response_tokens += response_tokens\n",
    "            total_tokens_left += unused_tokens\n",
    "\n",
    "            batch_results = json.loads(response_content)\n",
    "            results.update(batch_results)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch: {e}\")\n",
    "\n",
    "    return {\n",
    "        \"results\": results,\n",
    "        \"token_summary\": {\n",
    "            \"total_prompt_tokens\": total_prompt_tokens,\n",
    "            \"total_response_tokens\": total_response_tokens,\n",
    "            \"total_tokens_used\": total_prompt_tokens + total_response_tokens,\n",
    "            \"total_tokens_left_on_table\": total_tokens_left\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "results0_10 = extract_alcaldia_colonia_zip(df['formatted_address'].to_list()[0:10],API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = [{'alcaldia':v['alcaldia'], 'colonia':v['colonia'], 'zip_code':v['zip_code']} for v in results0_10['results'].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 801\n",
      "- Max allowed response tokens: 3295\n",
      "- Response tokens: 1513\n",
      "- Tokens left on table: 1782\n",
      "- Total used: 2314\n"
     ]
    }
   ],
   "source": [
    "results10_30 = extract_alcaldia_colonia_zip(df['formatted_address'].to_list()[10:30],API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = [{'alcaldia':v['alcaldia'], 'colonia':v['colonia'], 'zip_code':v['zip_code']} for v in results10_30['results'].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1070\n",
      "- Max allowed response tokens: 3026\n",
      "- Response tokens: 2152\n",
      "- Tokens left on table: 874\n",
      "- Total used: 3222\n"
     ]
    }
   ],
   "source": [
    "results30_60 = extract_alcaldia_colonia_zip(df['formatted_address'].to_list()[30:60],API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = [{'alcaldia':v['alcaldia'], 'colonia':v['colonia'], 'zip_code':v['zip_code']} for v in results30_60['results'].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1091\n",
      "- Max allowed response tokens: 3005\n",
      "- Response tokens: 2206\n",
      "- Tokens left on table: 799\n",
      "- Total used: 3297\n"
     ]
    }
   ],
   "source": [
    "results60_90 = extract_alcaldia_colonia_zip(df['formatted_address'].to_list()[60:90],API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4 = [{'alcaldia':v['alcaldia'], 'colonia':v['colonia'], 'zip_code':v['zip_code']} for v in results60_90['results'].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk= []\n",
    "for i in range(90, len(df['formatted_address']), 30):\n",
    "    results109 = df[['ciclo_estacionarribo']].iloc[i:i+30,:].reset_index()\n",
    "    kk.append(results109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_index = pd.concat(kk).drop(columns='index').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 120\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1100\n",
      "- Max allowed response tokens: 2996\n",
      "- Response tokens: 2202\n",
      "- Tokens left on table: 794\n",
      "- Total used: 3302\n",
      "120 150\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1151\n",
      "- Max allowed response tokens: 2945\n",
      "- Response tokens: 2263\n",
      "- Tokens left on table: 682\n",
      "- Total used: 3414\n",
      "150 180\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1141\n",
      "- Max allowed response tokens: 2955\n",
      "- Response tokens: 2260\n",
      "- Tokens left on table: 695\n",
      "- Total used: 3401\n",
      "180 210\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1089\n",
      "- Max allowed response tokens: 3007\n",
      "- Response tokens: 2190\n",
      "- Tokens left on table: 817\n",
      "- Total used: 3279\n",
      "210 240\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1140\n",
      "- Max allowed response tokens: 2956\n",
      "- Response tokens: 2241\n",
      "- Tokens left on table: 715\n",
      "- Total used: 3381\n",
      "240 270\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1137\n",
      "- Max allowed response tokens: 2959\n",
      "- Response tokens: 2250\n",
      "- Tokens left on table: 709\n",
      "- Total used: 3387\n",
      "270 300\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1169\n",
      "- Max allowed response tokens: 2927\n",
      "- Response tokens: 2277\n",
      "- Tokens left on table: 650\n",
      "- Total used: 3446\n",
      "300 330\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1189\n",
      "- Max allowed response tokens: 2907\n",
      "- Response tokens: 2332\n",
      "- Tokens left on table: 575\n",
      "- Total used: 3521\n",
      "330 360\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1182\n",
      "- Max allowed response tokens: 2914\n",
      "- Response tokens: 2326\n",
      "- Tokens left on table: 588\n",
      "- Total used: 3508\n",
      "360 390\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1150\n",
      "- Max allowed response tokens: 2946\n",
      "- Response tokens: 2260\n",
      "- Tokens left on table: 686\n",
      "- Total used: 3410\n",
      "390 420\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1162\n",
      "- Max allowed response tokens: 2934\n",
      "- Response tokens: 2264\n",
      "- Tokens left on table: 670\n",
      "- Total used: 3426\n",
      "420 450\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1172\n",
      "- Max allowed response tokens: 2924\n",
      "- Response tokens: 2294\n",
      "- Tokens left on table: 630\n",
      "- Total used: 3466\n",
      "450 480\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1202\n",
      "- Max allowed response tokens: 2894\n",
      "- Response tokens: 2338\n",
      "- Tokens left on table: 556\n",
      "- Total used: 3540\n",
      "480 510\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1180\n",
      "- Max allowed response tokens: 2916\n",
      "- Response tokens: 2270\n",
      "- Tokens left on table: 646\n",
      "- Total used: 3450\n",
      "510 540\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1114\n",
      "- Max allowed response tokens: 2982\n",
      "- Response tokens: 2189\n",
      "- Tokens left on table: 793\n",
      "- Total used: 3303\n",
      "540 570\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1153\n",
      "- Max allowed response tokens: 2943\n",
      "- Response tokens: 2247\n",
      "- Tokens left on table: 696\n",
      "- Total used: 3400\n",
      "570 600\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1126\n",
      "- Max allowed response tokens: 2970\n",
      "- Response tokens: 2214\n",
      "- Tokens left on table: 756\n",
      "- Total used: 3340\n",
      "600 630\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1148\n",
      "- Max allowed response tokens: 2948\n",
      "- Response tokens: 2246\n",
      "- Tokens left on table: 702\n",
      "- Total used: 3394\n",
      "630 660\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1164\n",
      "- Max allowed response tokens: 2932\n",
      "- Response tokens: 2266\n",
      "- Tokens left on table: 666\n",
      "- Total used: 3430\n",
      "660 690\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 1100\n",
      "- Max allowed response tokens: 2996\n",
      "- Response tokens: 2192\n",
      "- Tokens left on table: 804\n",
      "- Total used: 3292\n",
      "690 720\n",
      "\n",
      "Batch 1:\n",
      "- Prompt tokens: 214\n",
      "- Max allowed response tokens: 3882\n",
      "- Response tokens: 361\n",
      "- Tokens left on table: 3521\n",
      "- Total used: 575\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "\n",
    "for i in range(90, len(df['formatted_address']), 30):\n",
    "    print(i,i+30)\n",
    "    results = extract_alcaldia_colonia_zip(df['formatted_address'].to_list()[i:i+30], API_KEY)\n",
    "    results_list.append(results['results'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### How to save the results to a json file\n",
    "with open('/Volumes/T7 Shield/Ecobici/alcaldias_colonias_zips.json', 'w') as f:\n",
    "    json.dump(results_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract alcaldia, colonia, and zip_code\n",
    "loo = []\n",
    "for i in range(0, len(results_list)):\n",
    "    result = [{'alcaldia':v['alcaldia'], 'colonia':v['colonia'], 'zip_code':v['zip_code']} for v in results_list[i].values()]\n",
    "    loo.append(pd.DataFrame(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_final = pd.concat(loo).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.concat([df[['ciclo_estacionarribo']].iloc[0:10,:], pd.DataFrame(result1)], axis=1)\n",
    "b = pd.concat([df[['ciclo_estacionarribo']].iloc[10:30,:].reset_index(), pd.DataFrame(result2)], axis=1)\n",
    "c = pd.concat([df[['ciclo_estacionarribo']].iloc[30:60,:].reset_index(), pd.DataFrame(result3)], axis=1)\n",
    "d = pd.concat([df[['ciclo_estacionarribo']].iloc[60:90,:].reset_index(), pd.DataFrame(result4)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stations = pd.concat([stations_index, stations_final], axis=1)\n",
    "stations__final = pd.concat([a,b,c,d,all_stations], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations__final.to_csv('/Volumes/T7 Shield/Ecobici/stations_alcaldias_colonias_zips.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
